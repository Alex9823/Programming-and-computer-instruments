{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "-from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(input = 'filename', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_paths(directory):\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if os.path.splitext(name)[1] == '.txt':\n",
    "                paths.append(os.path.join(root, name))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_count_matrix(paths): # принимает список путей к файлам возвращает матрицу частотности (строки - документы, столбцы - слова)\n",
    "    X = vectorizer.fit_transform(paths)\n",
    "    matrix = X.toarray()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(count_matrix):\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf_matrix = transformer.fit_transform(count_matrix)\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_list(count_matrix):\n",
    "    return np.sum(count_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency_dictionary(freq_list, vocabulary):\n",
    "    freq_dict = {}\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        freq_dict[word] = word_freq[i]\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_frequent(freq_list, vocabulary, n=10):\n",
    "    indices = np.argpartition(freq_list, -n)[-n:]\n",
    "    most_freq_dict = dict(zip(vocabulary[indices], freq_list[indices]))\n",
    "    return most_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_least_frequent(freq_list, vocabulary, n=1):\n",
    "    indices = np.argpartition(freq_list, n)[n:]\n",
    "    least_freq_dict = dict(zip(vocabulary[indices], freq_list[indices]))\n",
    "    return least_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_indexation(matrix):\n",
    "    list_of_words = vectorizer.vocabulary_\n",
    "    by_id = np.apply_along_axis(lambda col: [x[0] for x in sorted(enumerate(col), key=lambda x:x[1], reverse=True)], 0, matrix) \n",
    "    return dict(zip(list_of_words, by_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('росс', array([114,  48, 145, ...,  56,  68,  65])), ('меня', array([107,  91,   0, ...,   0,   0,   0])), ('поцеловал', array([50, 47,  1, ...,  1,  1,  1])), ('боже', array([89, 55,  2, ...,  2,  2,  2])), ('мой', array([ 2, 56,  3, ...,  3,  3,  3])), ('сама', array([ 16, 103,   4, ...,   4,   4,   4])), ('не', array([ 54, 120,   5, ...,   5,   5,   5])), ('верю', array([82,  0,  6, ...,  6,  6,  6])), ('мы', array([125,   1,   7, ...,   7,   7,   7])), ('хотим', array([132,   2,   8, ...,   8,   8,   8]))]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    loc = os.path.join(os.getcwd(),'friends')\n",
    "    paths = directory_paths(loc)\n",
    "    count_matrix = fit_count_matrix(paths)\n",
    "    tfidf = tfidf_transform(count_matrix)\n",
    "    vocabulary = np.array(vectorizer.get_feature_names())\n",
    "    freq_list = get_freq_list(count_matrix)\n",
    "    print(list(get_reverse_indexation(count_matrix).items())[:10])\n",
    "#самое частотное слово\n",
    "\n",
    "    most_frequent_word = get_n_most_frequent(freq_list, vocabulary, n=1)\n",
    "#самое редкое слово\n",
    "\n",
    "    least_frequent_words = get_n_least_frequent(freq_list, vocabulary)\n",
    "#набор слов, который есть во всех документах коллекции\n",
    "    in_all_texts_bool = np.apply_along_axis(lambda x: 1 if not 0 in x else 0, 0, count_matrix)\n",
    "    in_all_texts = vocabulary[np.argmax(in_all_texts_bool)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "          main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
